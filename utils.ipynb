{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utility Functions for Deep Learning Workflows\n",
        "\n",
        "This notebook contains utility functions and examples for common deep learning tasks in PyTorch. It demonstrates:\n",
        "\n",
        "# Table of Contents\n",
        "1. [Kernel Connection Information](#kernel-connection-information)\n",
        "2. [Module Auto-reloading Setup](#module-auto-reloading-setup)  \n",
        "3. [Example Usage: Data Loading and Preprocessing](#example-usage-data-loading-and-preprocessing)\n",
        "\n",
        "\n",
        "The following cells provide practical examples of these utilities in action.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added d:\\Development\\Python\\PyTorch to Python path\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "\"\"\"Only needed for this util notebook cuz it's in the utils folder\"\"\"\n",
        "\"\"\"Add the project root directory to Python path.\"\"\"\n",
        "# Get the absolute path of this file's directory\n",
        "# In Jupyter notebooks, __file__ is not defined\n",
        "# Use notebook's directory instead\n",
        "try:\n",
        "    # Try to get the notebook's directory\n",
        "    current_dir = os.getcwd()\n",
        "except:\n",
        "    # Fallback if that doesn't work\n",
        "    current_dir = os.path.abspath('.')\n",
        "# Get the parent directory (project root)\n",
        "project_root = os.path.dirname(current_dir)\n",
        "# Add to Python path if not already there\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "    print(f\"Added {project_root} to Python path\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kernel Connection Information\n",
        "\n",
        "The following code cell retrieves and displays information about the current Jupyter kernel connection. It:\n",
        "\n",
        "1. Accesses the IPython kernel configuration\n",
        "2. Reads the connection file to extract port information\n",
        "3. Prints the port number where the kernel is running\n",
        "\n",
        "This is useful for debugging connection issues or when you need to connect to the kernel programmatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel is running on port: 9012\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from IPython.core.getipython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "if ipython is not None and hasattr(ipython.config, 'IPKernelApp'):\n",
        "    connection_file = ipython.config['IPKernelApp']['connection_file']\n",
        "    with open(connection_file) as f:\n",
        "        config = json.load(f)\n",
        "    print(f\"Kernel is running on port: {config['shell_port']}\")\n",
        "else:\n",
        "    print(\"Not running in an IPython kernel or kernel information not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module Auto-reloading Setup\n",
        "\n",
        "The following code cell demonstrates how to set up module auto-reloading in Jupyter. It:\n",
        "\n",
        "1. Imports necessary modules from the utils package\n",
        "2. Enables the autoreload extension with `%load_ext autoreload`\n",
        "3. Configures it to automatically reload all modules before executing code with `%autoreload 2`\n",
        "\n",
        "This is particularly useful during development when you're frequently making changes to imported modules and want those changes to be reflected without restarting the kernel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autoreload enabled: Changes to imported modules will be reloaded automatically\n"
          ]
        }
      ],
      "source": [
        "from utils import get_dataloaders, torch, TensorDataset\n",
        "\n",
        "# Enable autoreload extension\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# This will automatically reload modules before executing code\n",
        "# Useful during development when you're frequently changing code in imported modules\n",
        "print(\"Autoreload enabled: Changes to imported modules will be reloaded automatically\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Usage: Data Loading and Preprocessing\n",
        "\n",
        "This example demonstrates how to use the `get_preprocessed_dataloaders` function to create data loaders with automatic preprocessing. It shows:\n",
        "\n",
        "- Creating synthetic training and validation datasets\n",
        "- Defining a preprocessing function for data normalization \n",
        "- Setting up DataLoaders with automatic preprocessing\n",
        "- Inspecting the resulting batch sizes and data shapes\n",
        "\n",
        "The code illustrates proper usage of the data loading utilities with preprocessing capabilities.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of batches in training loader: 4\n",
            "Number of batches in validation loader: 1\n",
            "Batch shape: X=torch.Size([32, 5]), y=torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Example script demonstrating how to use get_dataloaders properly\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Create some sample data\n",
        "# For example, 100 samples with 5 features\n",
        "from utils import get_preprocessed_dataloaders\n",
        "\n",
        "\n",
        "x_train = torch.randn(100, 5)\n",
        "y_train = torch.randint(0, 2, (100,))\n",
        "\n",
        "x_valid = torch.randn(20, 5)\n",
        "y_valid = torch.randint(0, 2, (20,))\n",
        "\n",
        "# Create TensorDataset objects\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "valid_ds = TensorDataset(x_valid, y_valid)\n",
        "# Define a preprocessing function to normalize the data\n",
        "def preprocess(x, y):\n",
        "    # Normalize the input data to have zero mean and unit variance\n",
        "    mean = x.mean(0, keepdim=True)\n",
        "    std = x.std(0, keepdim=True) + 1e-7  # Add small epsilon to avoid division by zero\n",
        "    x_normalized = (x - mean) / std\n",
        "    return x_normalized, y\n",
        "\n",
        "# Create preprocessed dataloaders with batch size of 32\n",
        "train_loader, valid_loader = get_preprocessed_dataloaders(\n",
        "    train_ds=train_ds,\n",
        "    valid_ds=valid_ds,\n",
        "    bs=32,\n",
        "    preprocess=preprocess\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Number of batches in training loader: {len(train_loader)}\")\n",
        "print(f\"Number of batches in validation loader: {len(valid_loader)}\")\n",
        "\n",
        "# Get one batch from the training loader\n",
        "for X_batch, y_batch in train_loader:\n",
        "    print(f\"Batch shape: X={X_batch.shape}, y={y_batch.shape}\")\n",
        "    break "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
